{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.642857</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.490000</td>\n",
       "      <td>123432400.0</td>\n",
       "      <td>30.572857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.798571</td>\n",
       "      <td>30.464285</td>\n",
       "      <td>30.657143</td>\n",
       "      <td>150476200.0</td>\n",
       "      <td>30.625713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.747143</td>\n",
       "      <td>30.107143</td>\n",
       "      <td>30.625713</td>\n",
       "      <td>138040000.0</td>\n",
       "      <td>30.138571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.285715</td>\n",
       "      <td>29.864286</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>119282800.0</td>\n",
       "      <td>30.082857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>30.285715</td>\n",
       "      <td>29.865715</td>\n",
       "      <td>30.042856</td>\n",
       "      <td>111902700.0</td>\n",
       "      <td>30.282858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High        Low       Open       Volume  Adj Close\n",
       "Date                                                               \n",
       "2010-01-04  30.642857  30.340000  30.490000  123432400.0  30.572857\n",
       "2010-01-05  30.798571  30.464285  30.657143  150476200.0  30.625713\n",
       "2010-01-06  30.747143  30.107143  30.625713  138040000.0  30.138571\n",
       "2010-01-07  30.285715  29.864286  30.250000  119282800.0  30.082857\n",
       "2010-01-08  30.285715  29.865715  30.042856  111902700.0  30.282858"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/AAPL.csv\", index_col = 0)\n",
    "df[\"Adj Close\"] = df.Close # Moving close to the last column\n",
    "df.drop(['Close'], 1, inplace=True) # Moving close to the last column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.244034</td>\n",
       "      <td>0.015330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.016218</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.302982</td>\n",
       "      <td>0.015589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>0.013370</td>\n",
       "      <td>0.014455</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>0.275875</td>\n",
       "      <td>0.013208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.013256</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.234989</td>\n",
       "      <td>0.012936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.013263</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.218903</td>\n",
       "      <td>0.013913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                High       Low      Open    Volume  Adj Close\n",
       "Date                                                         \n",
       "2010-01-04  0.012862  0.015604  0.014799  0.244034   0.015330\n",
       "2010-01-05  0.013620  0.016218  0.015621  0.302982   0.015589\n",
       "2010-01-06  0.013370  0.014455  0.015466  0.275875   0.013208\n",
       "2010-01-07  0.011124  0.013256  0.013618  0.234989   0.012936\n",
       "2010-01-08  0.011124  0.013263  0.012599  0.218903   0.013913"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_data(df):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "    df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "    df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "    df['Volume'] = min_max_scaler.fit_transform(df.Volume.values.reshape(-1,1))\n",
    "    df['Adj Close'] = min_max_scaler.fit_transform(df['Adj Close'].values.reshape(-1,1))\n",
    "    return df\n",
    "df = normalize_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and testing set\n",
    "\n",
    "def load_data(stock, seq_len):\n",
    "    features = len(stock.columns) # five features\n",
    "    data = stock.values\n",
    "    sequence_length = seq_len+1 # +1 because index starts from 0\n",
    "    result = []\n",
    "    # maximum date = latest date - sequence length\n",
    "    # there is at most 22 trading days in one month\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        # index: index + 22 days\n",
    "        result.append(data[index:index+sequence_length])\n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90 percent split\n",
    "    train = result[:int(row), :] # 90 percent of  date, all features\n",
    "    \n",
    "    x_train = train[:, :-1] \n",
    "    y_train = train[:,-1][:,-1]\n",
    "    \n",
    "    x_test = result[int(row):,:-1] \n",
    "    y_test = result[int(row):,-1][:,-1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], features))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], features))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "def build_model(layers):\n",
    "    d = 0.3\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n",
    "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
    "    \n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "        \n",
    "    start = time.time()\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.28624937e-02 1.56041766e-02 1.47987840e-02 2.44034312e-01\n",
      "  1.53304812e-02]\n",
      " [1.36203369e-02 1.62176212e-02 1.56209386e-02 3.02982342e-01\n",
      "  1.55887783e-02]\n",
      " [1.33700432e-02 1.44548424e-02 1.54663419e-02 2.75874854e-01\n",
      "  1.32082264e-02]\n",
      " [1.11243252e-02 1.32561491e-02 1.36182554e-02 2.34989328e-01\n",
      "  1.29359668e-02]\n",
      " [1.11243252e-02 1.32632004e-02 1.25993413e-02 2.18902744e-01\n",
      "  1.39133238e-02]\n",
      " [1.18195926e-02 1.28330803e-02 1.43560846e-02 2.26868983e-01\n",
      "  1.26078571e-02]\n",
      " [9.57386525e-03 1.14016940e-02 1.18193493e-02 2.98925222e-01\n",
      "  1.09393745e-02]\n",
      " [1.03803784e-02 9.76582923e-03 1.08917972e-02 3.05155092e-01\n",
      "  1.29848356e-02]\n",
      " [1.00536033e-02 1.32349952e-02 1.24658353e-02 2.10883102e-01\n",
      "  1.21331411e-02]\n",
      " [1.08462108e-02 1.10138817e-02 1.30420407e-02 2.98711609e-01\n",
      "  9.68975789e-03]\n",
      " [1.33422318e-02 1.19798914e-02 1.12150355e-02 3.72789542e-01\n",
      "  1.60495318e-02]\n",
      " [1.35925254e-02 1.35734483e-02 1.58387794e-02 3.08566796e-01\n",
      "  1.37387924e-02]\n",
      " [1.20351219e-02 1.19587375e-02 1.38501411e-02 3.06387944e-01\n",
      "  1.11837091e-02]\n",
      " [7.99560319e-03 4.87233766e-03 1.01258595e-02 4.55488284e-01\n",
      "  3.97922200e-03]\n",
      " [6.04884884e-03 7.00883551e-03 7.12534355e-03 5.55718551e-01\n",
      "  7.69316563e-03]\n",
      " [1.23132363e-02 8.69405936e-03 9.54261768e-03 9.92431997e-01\n",
      "  9.69673914e-03]\n",
      " [1.01370376e-02 6.54345890e-03 1.01750400e-02 9.13666785e-01\n",
      "  1.10510746e-02]\n",
      " [6.60506835e-03 5.95821014e-03 8.82586986e-03 6.14463648e-01\n",
      "  5.05430726e-03]\n",
      " [4.31067101e-03 0.00000000e+00 6.12048368e-03 6.53943906e-01\n",
      "  6.98125474e-06]\n",
      " [0.00000000e+00 7.40368026e-04 0.00000000e+00 3.83616668e-01\n",
      "  1.87092967e-03]\n",
      " [2.22482233e-04 2.20700147e-03 2.48754536e-03 3.55534189e-01\n",
      "  2.65979281e-03]\n",
      " [2.92013617e-03 2.94032761e-03 1.96754762e-03 3.10297062e-01\n",
      "  5.01241974e-03]] 0.0\n"
     ]
    }
   ],
   "source": [
    "window = 22\n",
    "X_train, y_train, X_test, y_test = load_data(df, window)\n",
    "print (X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Compilation Time :  0.059839725494384766\n"
     ]
    }
   ],
   "source": [
    "model = build_model([5,window,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1795 samples, validate on 200 samples\n",
      "Epoch 1/90\n",
      "1795/1795 [==============================] - 3s 2ms/step - loss: 0.0810 - acc: 5.5710e-04 - val_loss: 0.1849 - val_acc: 0.0000e+00\n",
      "Epoch 2/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 0.0323 - acc: 5.5710e-04 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 3/90\n",
      "1795/1795 [==============================] - 2s 990us/step - loss: 0.0130 - acc: 5.5710e-04 - val_loss: 0.1378 - val_acc: 0.0000e+00\n",
      "Epoch 4/90\n",
      "1795/1795 [==============================] - 2s 960us/step - loss: 0.0161 - acc: 5.5710e-04 - val_loss: 0.0649 - val_acc: 0.0000e+00\n",
      "Epoch 5/90\n",
      "1795/1795 [==============================] - 2s 990us/step - loss: 0.0064 - acc: 5.5710e-04 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 6/90\n",
      "1795/1795 [==============================] - 2s 944us/step - loss: 0.0074 - acc: 5.5710e-04 - val_loss: 0.0591 - val_acc: 0.0000e+00\n",
      "Epoch 7/90\n",
      "1795/1795 [==============================] - 2s 970us/step - loss: 0.0041 - acc: 5.5710e-04 - val_loss: 0.0677 - val_acc: 0.0000e+00\n",
      "Epoch 8/90\n",
      "1795/1795 [==============================] - 2s 970us/step - loss: 0.0036 - acc: 5.5710e-04 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 9/90\n",
      "1795/1795 [==============================] - 2s 943us/step - loss: 0.0024 - acc: 5.5710e-04 - val_loss: 0.0183 - val_acc: 0.0000e+00\n",
      "Epoch 10/90\n",
      "1795/1795 [==============================] - 2s 966us/step - loss: 0.0019 - acc: 5.5710e-04 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 11/90\n",
      "1795/1795 [==============================] - 2s 961us/step - loss: 0.0021 - acc: 5.5710e-04 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 0.0015 - acc: 5.5710e-04 - val_loss: 0.0139 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 0.0013 - acc: 5.5710e-04 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 14/90\n",
      "1795/1795 [==============================] - 2s 966us/step - loss: 0.0012 - acc: 5.5710e-04 - val_loss: 0.0193 - val_acc: 0.0000e+00\n",
      "Epoch 15/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 9.6290e-04 - acc: 5.5710e-04 - val_loss: 0.0142 - val_acc: 0.0000e+00\n",
      "Epoch 16/90\n",
      "1795/1795 [==============================] - 2s 981us/step - loss: 8.9960e-04 - acc: 5.5710e-04 - val_loss: 0.0180 - val_acc: 0.0000e+00\n",
      "Epoch 17/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 8.9573e-04 - acc: 5.5710e-04 - val_loss: 0.0122 - val_acc: 0.0000e+00\n",
      "Epoch 18/90\n",
      "1795/1795 [==============================] - 2s 993us/step - loss: 7.5158e-04 - acc: 5.5710e-04 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 19/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 7.5080e-04 - acc: 5.5710e-04 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 20/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 7.1150e-04 - acc: 5.5710e-04 - val_loss: 0.0064 - val_acc: 0.0000e+00\n",
      "Epoch 21/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 6.8840e-04 - acc: 5.5710e-04 - val_loss: 0.0082 - val_acc: 0.0000e+00\n",
      "Epoch 22/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 7.0202e-04 - acc: 5.5710e-04 - val_loss: 0.0052 - val_acc: 0.0000e+00\n",
      "Epoch 23/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 6.2413e-04 - acc: 5.5710e-04 - val_loss: 0.0061 - val_acc: 0.0000e+00\n",
      "Epoch 24/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 6.3783e-04 - acc: 5.5710e-04 - val_loss: 0.0055 - val_acc: 0.0000e+00\n",
      "Epoch 25/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 6.0056e-04 - acc: 5.5710e-04 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 26/90\n",
      "1795/1795 [==============================] - 2s 992us/step - loss: 6.4251e-04 - acc: 5.5710e-04 - val_loss: 0.0047 - val_acc: 0.0000e+00\n",
      "Epoch 27/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 6.2019e-04 - acc: 5.5710e-04 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 28/90\n",
      "1795/1795 [==============================] - 2s 990us/step - loss: 5.8854e-04 - acc: 5.5710e-04 - val_loss: 0.0037 - val_acc: 0.0000e+00\n",
      "Epoch 29/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 6.0309e-04 - acc: 5.5710e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 30/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.7072e-04 - acc: 5.5710e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 31/90\n",
      "1795/1795 [==============================] - 2s 966us/step - loss: 5.5229e-04 - acc: 5.5710e-04 - val_loss: 0.0035 - val_acc: 0.0000e+00\n",
      "Epoch 32/90\n",
      "1795/1795 [==============================] - 2s 997us/step - loss: 5.3910e-04 - acc: 5.5710e-04 - val_loss: 0.0030 - val_acc: 0.0000e+00\n",
      "Epoch 33/90\n",
      "1795/1795 [==============================] - 2s 975us/step - loss: 5.7189e-04 - acc: 5.5710e-04 - val_loss: 0.0026 - val_acc: 0.0000e+00\n",
      "Epoch 34/90\n",
      "1795/1795 [==============================] - 2s 988us/step - loss: 5.7638e-04 - acc: 5.5710e-04 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 35/90\n",
      "1795/1795 [==============================] - 2s 986us/step - loss: 5.4333e-04 - acc: 5.5710e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 36/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.3110e-04 - acc: 5.5710e-04 - val_loss: 0.0027 - val_acc: 0.0000e+00\n",
      "Epoch 37/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.2900e-04 - acc: 5.5710e-04 - val_loss: 0.0024 - val_acc: 0.0000e+00\n",
      "Epoch 38/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.3729e-04 - acc: 5.5710e-04 - val_loss: 0.0021 - val_acc: 0.0000e+00\n",
      "Epoch 39/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.4432e-04 - acc: 5.5710e-04 - val_loss: 0.0028 - val_acc: 0.0000e+00\n",
      "Epoch 40/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.1923e-04 - acc: 5.5710e-04 - val_loss: 0.0022 - val_acc: 0.0000e+00\n",
      "Epoch 41/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.0062e-04 - acc: 5.5710e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 42/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.1424e-04 - acc: 5.5710e-04 - val_loss: 0.0019 - val_acc: 0.0000e+00\n",
      "Epoch 43/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.1206e-04 - acc: 5.5710e-04 - val_loss: 0.0017 - val_acc: 0.0000e+00\n",
      "Epoch 44/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.0434e-04 - acc: 5.5710e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 45/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 5.0983e-04 - acc: 5.5710e-04 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 46/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 4.8876e-04 - acc: 5.5710e-04 - val_loss: 0.0016 - val_acc: 0.0000e+00\n",
      "Epoch 47/90\n",
      "1795/1795 [==============================] - 2s 1ms/step - loss: 4.8181e-04 - acc: 5.5710e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 48/90\n",
      "1795/1795 [==============================] - 2s 974us/step - loss: 4.6063e-04 - acc: 5.5710e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 49/90\n",
      "1795/1795 [==============================] - 2s 972us/step - loss: 4.5707e-04 - acc: 5.5710e-04 - val_loss: 9.9404e-04 - val_acc: 0.0000e+00\n",
      "Epoch 50/90\n",
      "1795/1795 [==============================] - 2s 961us/step - loss: 4.4049e-04 - acc: 5.5710e-04 - val_loss: 0.0012 - val_acc: 0.0000e+00\n",
      "Epoch 51/90\n",
      "1795/1795 [==============================] - 2s 953us/step - loss: 4.4903e-04 - acc: 5.5710e-04 - val_loss: 7.1998e-04 - val_acc: 0.0000e+00\n",
      "Epoch 52/90\n",
      "1795/1795 [==============================] - 2s 980us/step - loss: 4.7369e-04 - acc: 5.5710e-04 - val_loss: 9.4880e-04 - val_acc: 0.0000e+00\n",
      "Epoch 53/90\n",
      "1795/1795 [==============================] - 2s 957us/step - loss: 4.4597e-04 - acc: 5.5710e-04 - val_loss: 0.0018 - val_acc: 0.0000e+00\n",
      "Epoch 54/90\n",
      "1795/1795 [==============================] - 2s 976us/step - loss: 4.5369e-04 - acc: 5.5710e-04 - val_loss: 0.0014 - val_acc: 0.0000e+00\n",
      "Epoch 55/90\n",
      "1795/1795 [==============================] - 2s 967us/step - loss: 4.4204e-04 - acc: 5.5710e-04 - val_loss: 7.7735e-04 - val_acc: 0.0000e+00\n",
      "Epoch 56/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 2s 957us/step - loss: 4.2164e-04 - acc: 5.5710e-04 - val_loss: 4.9196e-04 - val_acc: 0.0000e+00\n",
      "Epoch 57/90\n",
      "1024/1795 [================>.............] - ETA: 0s - loss: 4.8709e-04 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=512,epochs=90,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=[]\n",
    "ratio=[]\n",
    "p = model.predict(X_test)\n",
    "# for each data index in test data\n",
    "for i in range(len(y_test)):\n",
    "    # pr = prediction day i\n",
    "    pr = p[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/AAPL.csv\", index_col = 0)\n",
    "df[\"Adj Close\"] = df.Close # Moving close to the last column\n",
    "df.drop(['Close'], 1, inplace=True) # Moving close to the last column\n",
    "\n",
    "# Bug fixed at here, please update the denormalize function to this one\n",
    "def denormalize(df, normalized_value): \n",
    "    df = df['Adj Close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new\n",
    "\n",
    "newp = denormalize(df, p)\n",
    "newy_test = denormalize(df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]\n",
    "\n",
    "\n",
    "model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(newp,color='orange', label='Prediction')\n",
    "plt2.plot(newy_test,color='green', label='Actual')\n",
    "plt2.legend(loc='best')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
